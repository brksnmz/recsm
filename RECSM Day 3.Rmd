---
title: 'RECSM: Quantitative Methods in Social Research'
author: "Burak Sonmez"
subtitle: Day 3 - 04 07 2025
output:
  pdf_document: default
  html_document:
    df_print: paged
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

**Measurement of the Unobserved Variables and Scale Construction.**

## Final Problem Set

**Step 1**: Open a new script and save it as day3. Clear your workspace.

**Step 2**: Load the General Social Survey (gss2016.RData) dataset and install "Psych" alongside "psychTools" package.

**Step 3**: Once you subset the ten variables related to confidence in institutions, you can explore the correlations among those variables in the dataset. 

**Step 4**: Try to create a new variable that combines all 10 likert-scale variables (hint: use rowMeans function).  

**Step 5**: Test the reliability of this scale through Cronbach's alpha (hint: use "alpha" function. 

**Step 6**: Test for the number of factors in your data using parallel analysis. 

**Step 7**: Do the same analysis above with Principle Component Analysis (PCA).

**Step 8**: Use factor analysis with the data. Then compare the solution to a hierarchical cluster analysis using the "ICLUST" algorithm and function (Revelle, 1979). 

## Solutions for problem sets

```{r prob1, include=TRUE, echo=TRUE}
#Remove objects from the environment
rm(list=ls())
#Set your working directory
setwd("~/Downloads/RECSM workshop")
#Load the dataset
load("gss2016.RData")
#Install the package psych
install.packages( "psych" , repos = "http://cran.rstudio.com/" )
install.packages( "psychTools" , repos = "http://cran.rstudio.com/" )
install.packages( "corrplot" , repos = "http://cran.rstudio.com/" )
library(psych)
library(psychTools)
library(corrplot)

## Subsetting some variables related to confidence in institutions.
confvars <- c("confinan","conbus", "conclerg", "coneduc",
"conpress", "contv", "conjudge", "consci",
"conlegis", "conarmy")
confdata <- gss[confvars]
lowerCor(confdata)

## Find out relatively stronger correlations.
round(cor(confdata, use='pairwise'), 2)
cor <- cor(confdata)

#At first glance, there appears to be some 
#association among confidence in different institutions.

## Creating a variable combining 10 likert scale questions.
confdata$con.scale <- rowMeans(confdata, na.rm=FALSE)
range(confdata$con.scale, na.rm=T)

#Find coefficient alpha as an estimate of reliability. This may be done for a single scale. Interpret the score. 
alpha(confdata)

##Test for the number of factors in your data using parallel analysis
fa.parallel(confdata)

#Let’s start with principal component analysis (PCA). 
#The default function consists of one component.
#However, you can change this by using the argument. 
#Please see all the arguments for PCA, using help function.
#In using PCA, the goal can be only data reduction, 
#but the interpretation of components is frequently done
#in terms similar to those used when describing 
#the latent variables estimated by FA. 
#PCA reports the largest n eigen vectors 
#rescaled by the square root of their eigen values.
principal(confdata)
## Retaining two factors instead of one. Check the results and identify the differences.
principal(confdata, nfactors = 2)

#The parallel factors technique compares 
#the observed eigen values of a correlation matrix 
#with those from random data.
#We could fit a one-factor model to these data 
#in which all ten indicators are thought to reflect a common
#latent factor. Here, we estimate this factor using maximum likelihood.
conf1 <- fa(confdata, nfactors=1, fm="ml")
conf1

##We see that much of the variation in finance, business,judge,
##legislation, and education is explained by the latent factor.
##However, only 28% and 39% variance in science and press is explained
##with low communality and high uniquenesses. This suggests
##a poor factor solution. Let’s compare against a 3-factor solution:
confactor <- fa(confdata, nfactors=3, fm="ml", rotate="oblimin")
confactor

##The paralel analysis suggests a 4-factor solution.
confactor <- fa(confdata, nfactors=4, fm="ml", rotate="oblimin")
##fa.plot will plot the loading from a factor, principal components,
##or cluster analysis.If there are more than two factors, then a SPLOM
##of the loadings is generated.
fa.plot(confactor)
##fa.diagram replaces fa.graph and will draw a path diagram representing
##the factor structure. It does not require Rgraphviz and
##thus is probably preferred.
fa.diagram(confactor)
#Item Cluster Analysis
iclust(confdata)
```